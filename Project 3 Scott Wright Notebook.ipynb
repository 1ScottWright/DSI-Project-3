{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Reddit's API for Predicting From Which Subreddit a Post Comes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data from subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I chose to compare two subreddits related to QUEENS.  My topic is to train a computer to tell the difference between a post from the Rupaul Drag Race subreddit (r/rupauldragrace) versus a post from a subreddit that is generally focused on royal families (r/monarchist).\n",
    "\n",
    "> I collected data at three points in time using the routine below.  I then have code that combines the scraped data into one dataframe and deletes duplicate data.  Overall, I ended up with approximately 1400 posts for my target subreddit (RDR) and almost 1000 posts for the other class, general monarchy posts.\n",
    "\n",
    "> Additionally, I have scraped a third subreddit, a discussion forum on the Netflix show The Crown (r/thecrown).  At the end of the exercise, I want to see if this post about this show resemble more closely posts from the RDR forum or the general monarchy forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries that will be used throughout the notebook\n",
    "\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from bs4 import BeautifulSoup             \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Select which subreddit to pull data from.  Set header for the reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.reddit.com/r/rupaulsdragrace.json\"\n",
    "#url = \"https://www.reddit.com/r/monarchism.json\"\n",
    "#url = 'https://www.reddit.com/r/TheCrownNetflix.json'\n",
    "\n",
    "header = {'User-agent': 'Scott data science student project 0.2'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The follwing code take 40 loops through the data to collect up to a 1000 posts.  Note that the reddit API only allows the most recent 1000 posts to be scraped, 25 at a time.  This loop maximizes the amount of data collected in one turn.  The print statements (now commented out) were useful in showing progress as the files were scrapped.\n",
    "#### This code is only run if additional data scraping is desired.  After data is scraped, the user only needs to load the data from the CSV files, and proceed to the modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "last = None\n",
    "for j in range(40):\n",
    "    if last == None:\n",
    "        param = {}\n",
    "    else:\n",
    "        param = {'after':last}\n",
    "    result = requests.get(url, params = param, headers = header)\n",
    "    if result.status_code == 200:\n",
    "        data = result.json()\n",
    "        posts.extend(data['data']['children'])\n",
    "        last = data['data']['after']\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The object posts is a list of dictionaries.  Each dictionary in the list contains a key 'data' which then accesses another dictionary.  This second dictionary contains the post data.  The code below iterates through the posts list, extracts the embedded dictionary, creates a Pandas dataframe, and then writes the data to a CSV file so that it can be used later in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dict = [each['data'] for each in posts]\n",
    "post_df = pd.DataFrame(post_dict)\n",
    "#fileout = './datasets/thecrown.csv'\n",
    "fileout = './datasets/ru_friday3.csv'\n",
    "#fileout = './datasets/royal_wednesday.csv'\n",
    "post_df.to_csv(fileout, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load scraped data from CSV files\n",
    "\n",
    "> The code below loads the files created as the data was scraped from reddit.  It then combines the files (in order from most recent to oldest), fills null values, drops duplicates, and then creates the datafield X which is a combination of the title of a post plus the text that goes along with the title.\n",
    "\n",
    "> It was required to fill null values because combining the title and post text returned a null value if either the title or text was null.  A space was inserted instead of a null which will not influence the NLP analysis.\n",
    "\n",
    "> Although the code looks repetitive, it was generated over the course of two weeks where new lines were added in as new data was collected.  It didn't make sense to go back after the fact to create functions.\n",
    "\n",
    "> The last block of code in this section puts the class labels on to the data (1 = RDR, 0 = general monarchy).  And then combines all of the data into one dataset so that it can then be passed to train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load save CSV files\n",
    "post_df1 = pd.read_csv('./datasets/ru.csv')          # ru.csv is from r/rupaulsdragrace\n",
    "post_df2 = pd.read_csv('./datasets/royal.csv')       # This royal.csv is from r/monarchism\n",
    "post_df1a = pd.read_csv('./datasets/ru_Sun.csv') \n",
    "post_df2a = pd.read_csv('./datasets/royal_Sun.csv') \n",
    "post_df1b = pd.read_csv('./datasets/ru_wednesday.csv')\n",
    "post_df2b = pd.read_csv('./datasets/royal_wednesday.csv')\n",
    "post_df3 = pd.read_csv('./datasets/thecrown.csv')\n",
    "\n",
    "# Combine files \n",
    "post_df1 = post_df1a.append(post_df1)\n",
    "post_df2 = post_df2a.append(post_df2)\n",
    "post_df1 = post_df1b.append(post_df1)\n",
    "post_df2 = post_df2b.append(post_df2)\n",
    "\n",
    "# Fill null values with spaces\n",
    "post_df1.fillna(' ', inplace = True)\n",
    "post_df2.fillna(' ', inplace = True)\n",
    "post_df3.fillna(' ', inplace = True)\n",
    "\n",
    "# Create one column with the text to be analyzed\n",
    "post_df1['X'] = post_df1['title'] + ' ' + post_df1['selftext']\n",
    "post_df2['X'] = post_df2['title'] + ' ' + post_df2['selftext']\n",
    "post_df3['X'] = post_df3['title'] + ' ' + post_df3['selftext']\n",
    "\n",
    "# Drop duplicate records -- highly likely since scrapes happened at various points in two weeks\n",
    "post_df1.drop_duplicates(subset = ['X'], keep = 'first', inplace = True)\n",
    "post_df2.drop_duplicates(subset = ['X'], keep = 'first', inplace = True)\n",
    "post_df3.drop_duplicates(subset = ['X'], keep = 'first', inplace = True)\n",
    "\n",
    "# Prep data so that modeling process can begin.\n",
    "post_df1['subred'] = 1   # 1 indicates subreddit RuPaul's drag race\n",
    "post_df2['subred'] = 0   # 0 indicates subreddit Monarchy\n",
    "X = post_df1[['X']]\n",
    "y = post_df1[['subred']]\n",
    "X = X.append(post_df2[['X']])\n",
    "y = y.append(post_df2[['subred']])\n",
    "X.reset_index(drop= True, inplace = True)            # Since the two subreddits had overlapping indices\n",
    "y.reset_index(drop= True, inplace = True)            # need to reset so that there are no conflicts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find mean of y so that we know the minimum performance of any model.\n",
    "\n",
    "> Given the mean is around 60%, any model that has an accuracy of around 60% is a very poor model.  Labeling all posts as 1 would produce this level of accuracy without any NLP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subred    0.597738\n",
      "dtype: float64\n",
      "subred    0.596774\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep / Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following data prep routine was used to prepare the data for analysis.\n",
    "\n",
    "> I did sensitivity test certain cleaning protocol to see if the impact on model accuracy.  For example, I turned Lemmatizing off and noticed poorer model performance.  I also kept stop words in place but again noticed (significant) model deterioration.\n",
    "\n",
    "> Many of these tasks could be handled by the models themselves, but I liked the idea of controlling the cleaning process.  Additionally, doing this step at the beginning allowed me to run multiple passes of the models without repeating these tasks each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(text_in):      \n",
    "    text_out = text_in.lower()                           #change everything to lower case\n",
    "    text_out = re.sub(\"\\\\n\", ' ', text_out)              #replace end of line \\n with space\n",
    "    text_out = re.sub(\"\\.[0-9a-z]+ \", ' ', text_out)     #eliminate .abc231 constucts\n",
    "    text_out = re.sub(\"[^a-z ]\", '', text_out)           #if not text, remove\n",
    "    tokenizer = RegexpTokenizer('\\w+')                   #instantiate Tokenizer\n",
    "    list_out = tokenizer.tokenize(text_out)              #split into words\n",
    "    lemmatizer = WordNetLemmatizer()                     #instantiate lemmatizer\n",
    "    list_out = [lemmatizer.lemmatize(each) for each in list_out]\n",
    "    list_out = [each for each in list_out if each not in stopwords.words('english')]\n",
    "    return  (' '.join(list_out))                         #smash words back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_f = X_train['X'].apply(data_prep)\n",
    "X_te_f = X_test['X'].apply(data_prep)\n",
    "X_crown = post_df3['X'].apply(data_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remove any entries where the post is blanks.  This can happen if the post only contained stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.DataFrame({\n",
    "    'X':X_tr_f,\n",
    "    'y':y_train['subred']\n",
    "})\n",
    "\n",
    "rmv = list(trn[trn['X'] == ''].index)\n",
    "\n",
    "trn.drop(labels = rmv, axis = 0, inplace = True)\n",
    "\n",
    "X_tr_f = trn['X']\n",
    "y_train = trn[['y']]\n",
    "\n",
    "trn = pd.DataFrame({\n",
    "    'X':X_te_f,\n",
    "    'y':y_test['subred']\n",
    "})\n",
    "\n",
    "rmv = list(trn[trn['X'] == ''].index)\n",
    "trn.drop(labels = rmv, axis = 0, inplace = True)\n",
    "\n",
    "X_te_f = trn['X']\n",
    "y_test = trn[['y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Look at most common words, which subreddit they came from, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a21b6d0f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAJQCAYAAADrDV68AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xu4XVV97//3B8QmmgAVAmqPIcEL1CCGZqOioNFyOBVvKFKqiIoegy1KW4vWWmvR1l/VWm2LkSZeEfGOiMUesUeIIPe9uUdBfgqBtlRFMQQIEeF7/lgzj9uYveeC7LXX2mu/X8+znz3XWGOO9V3rr88zxhxzpqqQJEmSJrNdvwuQJEnS4DM0SpIkqZWhUZIkSa0MjZIkSWplaJQkSVIrQ6MkSZJaGRolSZLUytAoSZKkVoZGSZIktXpIvwsYNrvuumstWrSo32VIkiS1Ghsbu62qFnTT19A4xRYtWsTo6Gi/y5AkSWqVZF23fV2eliRJUitDoyRJkloZGiVJktTK0ChJkqRWhkZJkiS1MjRKkiSplaFRkiRJrQyNkiRJamVolCRJUitDoyRJkloZGiVJktTK0ChJkqRWhkZJkiS1MjRKkiSplaFRkiRJrQyNkiRJamVolCRJUitDoyRJkloZGiVJktTK0ChJkqRWhkZJkiS1MjRKkiSplaFRkiRJrR7S7wKGzboNN3PsmuP6XYYkSZpGq5av7HcJPedMoyRJklrN6tCY5C1Jjm+OP5jknOb4d5N8OsnJSUaTrE3yzv5WK0mS1D+zOjQC5wEHNccjwLwkOwAHAucDf1lVI8C+wLOS7Lu1QZKsaMLl6D3rN05H3ZIkSdNqtofGMWBZkvnAJuAiOuHxIDqh8feTXA5cASwBnri1QapqdVWNVNXInJ3mTk/lkiRJ02hWb4SpqnuT3AQcA1wIXA08G3gssBE4Adi/qm5P8klgTp9KlSRJ6qtZHRob59EJh68BrgE+QGcGckfgLmB9kt2B5wJr2gbbY/7CWbGDSpIkzS6zfXkaOsvQjwIuqqofAvcA51fVVXSWpdcCHwcu6F+JkiRJ/ZWq6ncNQyVzdyn2PLTfZUiSpkmtPbXfJUgPWpKxZtNvK2caJUmS1MrQKEmSpFaGRkmSJLUyNEqSJKmVoVGSJEmtvE/jFFu2ZDGjo+6kkyRJw8WZRkmSJLUyNEqSJKmVoVGSJEmtDI2SJElqZWiUJElSK0OjJEmSWhkaJUmS1MrQKEmSpFaGRkmSJLWalU+ESXJnVc1L8mjgn6vqpUleDYxU1Ru2Zex1G27m2DXHTUmdkiRpdlq1fGW/S/g1szI0blZV/wW8tN91SJIkDbpZvTydZFGSa7fS/rwkFyXZNcmCJKcnuaz5e0Y/apUkSeqnWT3TuDVJXgy8CTi0qm5P8hngg1X17SQLgbOB397inBXACoB5u8+b7pIlSZJ6ztD4q54NjACHVNUdTdvBwBOTbO6zY5L5VbVhc0NVrQZWAyzYa7eaxnolSZKmhaHxV/0A2BN4AjDatG0HHFBVG/tWlSRJUp8ZGn/VOuAE4IwkR1TVWuAbwBuAvwdIsrSqrpxogD3mLxzIHU+SJEnbYlZvhNmaqroeOAr4YpLHAscDI0muTvId4PV9LVCSJKkPUuUleFMpc3cp9jy032VImiFq7an9LkHSLJZkrKpGuunrTKMkSZJaGRolSZLUytAoSZKkVoZGSZIktTI0SpIkqZX3aZxiy5YsZnTU3ZCSJGm4ONMoSZKkVoZGSZIktTI0SpIkqZWhUZIkSa0MjZIkSWplaJQkSVIrQ6MkSZJaGRolSZLUytAoSZKkVj4RZoqt23Azx645rt9lSJLUU6uWr+x3CZpmzjRKkiSp1YwOjUn+Msn1Sf5vks8mOSHJmiQjzfu7JrmpOd4+yd8nuSzJ1UmOHTfOm8e1v7NpW5Tku0k+kmRtkm8kmduXLypJktRnMzY0JlkG/AGwH/ASYP+WU14LrK+q/Zu+r0uyOMkhwOOBpwBLgWVJntmc83hgZVUtAX4GHD5BLSuSjCYZvWf9xm39apIkSQNnJl/TeBBwRlXdDZDkqy39DwH2TfLS5vVOdELhIc3fFU37vKb9ZuDGqrqyaR8DFm1t4KpaDawGWLDXbvVgvowkSdIgm8mhEWBrAe0X/HIGdc649gBvrKqzx3dO8r+Av6uqVVu0LwI2jWu6D3B5WpIkzUozOTSeB3wyyXvofI8XAKuAm4BlwKXAS8f1Pxv4wyTnVNW9SZ4A/GfT/jdJTquqO5P8FnDvgy1qj/kL3VEmSZKGzowNjVV1eZLPA1cC64Dzm7feD3whydHAOeNO+Sid5eXLkwT4MXBYVX0jyW8DF3WauRN4BZ2ZRUmSJAGpGo5L8JKcCNxZVe/vax1zdyn2PLSfJUjSUKu1p/a7BGloJBmrqpFu+s7Y3dOSJEmaPjN2eXpLVXViv2uQJEkaVs40SpIkqZWhUZIkSa0MjZIkSWo1NNc0DoplSxYzOurOPkmSNFycaZQkSVIrQ6MkSZJaGRolSZLUytAoSZKkVoZGSZIktTI0SpIkqZWhUZIkSa0MjZIkSWplaJQkSVIrnwgDJHk1MFJVb9jWsdZtuJlj1xy37UVJknpm1fKV/S5BmnFm1Uxjku37XYMkSdJMNO2hMcmiJNcl+WiSa5OcluTgJBckuSHJU5I8IslXklyd5OIk+zbnnpjk40nWJPlBkuPHjfuVJGNJ1iZZMa79ziTvSnIJcECS/ZNcmOSqJJcmmd90fXSSrzc1vK8597VJPjhurNcl+cD0/FKSJEmDo1/L048DjgBWAJcBLwcOBF4IvA24Bbiiqg5L8hzgU8DS5ty9gWcD84Hrk5xcVfcCr6mqnyaZC1yW5PSq+gnwcODaqnpHkocC1wFHVtVlSXYENjbjLgX2AzY1454EfA64Oslbms84Bjh2yy/ThNQVAPN2nzeFP5MkSdJg6Nfy9I1VdU1V3Q+sBb5ZVQVcAyyiEyBPBaiqc4BdkuzUnPu1qtpUVbcBPwJ2b9qPT3IVcDHwGODxTft9wOnN8V7ArVV1WTP2HVX1i+a9b1bV+qq6B/gOsEdV3QWcAzw/yd7ADlV1zZZfpqpWV9VIVY3M2WnuFPw8kiRJg6VfM42bxh3fP+71/XRq+sWvnQG1lXPvAx6SZDlwMHBAVd2dZA0wp+lzT1Xd1xxn3DiT1XQfv/xtPkpn9vM64BMTfyVJkqThNai7p88DjgL+pgmEt1XVHUkm6r8TcHsTGPcGnjZBv+voXLu4f7M8PZ9fLk9vVVVdkuQxwO8A+7YVvsf8he7KkyRJQ2dQQ+OJwCeSXA3cDbyqpf/Xgdc3/a+ns0T9a6rq50mOBE5qrn3cSGeGss0XgKVVdXuX9UuSJA2VdC4l1GSSnAV8sKq+2dp37i7FnodOQ1WSNP1q7an9LkHSFEoyVlUj3fSdVfdpfKCS7Jzke8DGbgKjJEnSsBrU5emBUFU/A57Q7zokSZL6zZlGSZIktTI0SpIkqZWhUZIkSa28pnGKLVuymNFRdxdKkqTh4kyjJEmSWhkaJUmS1MrQKEmSpFaGRkmSJLUyNEqSJKmVoVGSJEmtDI2SJElqZWiUJElSK0OjJEmSWvlEmC0kORG4s6rev0X7IuCsqtpnsvPXbbiZY9cc17P6JGk2WbV8Zb9LkNRwplGSJEmtZnxoTPKWJMc3xx9Mck5z/LtJPp3kZUmuSXJtkveOO+/OcccvTfLJrYy9LMlVSS4CnD6UJEmz1owPjcB5wEHN8QgwL8kOwIHADcB7gecAS4H9kxz2AMb+BHB8VR0wWackK5KMJhm9Z/3GB/wFJEmSBt0whMYxYFmS+cAm4CI64fEg4GfAmqr6cVX9AjgNeGY3gybZCdi5qr7VNJ06Ud+qWl1VI1U1MmenudvwVSRJkgbTjA+NVXUvcBNwDHAhcD7wbOCxwM2TnTrueM5W3s8WfSRJkmatYdk9fR5wAvAa4BrgA3RmIC8G/jHJrsDtwMuAk5pzfpjkt4HrgRcDG8YPWFU/S7I+yYFV9W3gqG4K2WP+Qnf7SZKkoTPjZxob5wOPAi6qqh8C9wDnV9WtwF8A5wJXAZdX1ZnNOW8FzgLOAW6dYNxjgJXNRhgvVpQkSbNWqlyBnUqZu0ux56H9LkOSJlRrJ7xEW9Isk2Ssqka66TssM42SJEnqIUOjJEmSWhkaJUmS1MrQKEmSpFaGRkmSJLUalvs0DoxlSxYzOurOREmSNFycaZQkSVIrQ6MkSZJaGRolSZLUytAoSZKkVoZGSZIktTI0SpIkqZWhUZIkSa0MjZIkSWplaJQkSVKrWfVEmCQnAndW1ft79RnrNtzMsWuO69XwkqStWLV8Zb9LkIberJ9pTDKrgrMkSdKDMfSBKclfAq8EbgF+DIwlWQNcCDwD+GqS7wFvBx4K/AQ4qqp+mGQB8BlgF+Ay4PeAZVV127R/EUmSpD4a6pnGJMuAPwD2A14C7D/u7Z2r6llV9Q/At4GnVdV+wOeAtzR9/ho4p6p+BzgDWDjB56xIMppk9J71G3v0bSRJkvpn2GcaDwLOqKq7AZJ8ddx7nx93/D+Azyd5FJ3Zxhub9gOBFwNU1deT3L61D6mq1cBqgAV77VZT+g0kSZIGwFDPNDYmCnF3jTs+CfhQVT0JOBaY07Snl4VJkiTNFMM+03ge8Mkk76HzXV8ArNpKv52A/2yOXzWu/dvA7wPvTXII8JttH7jH/IXu4pMkSUNnqGcaq+pyOsvQVwKnA+dP0PVE4ItJzgfGb3J5J3BIksuB5wK3Aht6VrAkSdKASpWX4E0kyW8A91XVL5IcAJxcVUsnPWfuLsWeh05PgRpatfbUfpcgSZoFkoxV1Ug3fYd9eXpbLQS+kGQ74OfA6/pcjyRJUl8YGidRVTfQuV2PJEnSrDbU1zRKkiRpahgaJUmS1MrQKEmSpFZe0zjFli1ZzOioO18lSdJwcaZRkiRJrQyNkiRJamVolCRJUitDoyRJkloZGiVJktTK0ChJkqRWhkZJkiS1MjRKkiSplaFRkiRJrXwiTCPJhVX19G0dZ92Gmzl2zXFTUZKkWWbV8pX9LkGSJuRMY2MqAqMkSdKwMjQ2ktzZ/F+e5FtJvpDke0nek+SoJJcmuSbJY/tdqyRJ0nQzNG7dk4E/Bp4EHA08oaqeAnwUeOOWnZOsSDKaZPSe9Runt1JJkqRpYGjcusuq6taq2gR8H/hG034NsGjLzlW1uqpGqmpkzk5zp7FMSZKk6WFo3LpN447vH/f6ftw8JEmSZiED0BTbY/5Cd0BKkqSh40yjJEmSWqWq+l3DUMncXYo9D+13GVKrWntqv0uQJPVZkrGqGummrzONkiRJamVolCRJUitDoyRJkloZGiVJktTK0ChJkqRW3qdxii1bspjRUXelSpKk4eJMoyRJkloZGiVJktTK0ChJkqRWhkZJkiS1MjRKkiSplaFRkiRJrQyNkiRJatUaGpM8I8nDm+NXJPlAkj16X5okSZIGRTczjScDdyd5MvAWYB3wqZ5WJUmSpIHSzRNhflFVleRFwD9V1ceSvKrXhU2lJIuAs6pqn3FtI8Arq+r4qfysdRtu5tg1x03lkJIGxKrlK/tdgiT1TTehcUOSvwBeATwzyfbADr0tq/eqahQY7XcdkiRJM0E3y9NHApuA11bVfwO/Bfx9T6vqoSR7JrkiyZuTnNW0nZjk40nWJPlBkuPH9f+rJNcl+fckn01yQv+qlyRJ6o9uZhr/tKr+fPOLqro5yZIe1tQzSfYCPgccA+wMPGvc23sDzwbmA9cnORl4MnA4sB+d3+pyYGwr464AVgDM231eD7+BJElSf3Qz0/g/t9L23KkuZBosAM4EXlFVV27l/a9V1aaqug34EbA7cCBwZlVtrKoNwL9ubeCqWl1VI1U1Mmenub2qX5IkqW8mnGlM8ofAHwGPTXL1uLfmAxf2urAeWA/cAjwDWLuV9zeNO76Pzm+TaahLkiRp4E22PP0Z4P8Afwe8dVz7hqr6aU+r6o2fA4cBZye5E/ivLs75NrAqyd/R+a2eB3xkshP2mL/QHZaSJGnoTLg8XVXrq+om4O3Af1fVOmAx8IokO09TfVOqqu4Cng/8KbBTF/0vA74KXAV8mc5u6/W9rFGSJGkQpaom75BcCYwAi4Cz6YSovarq0J5XNwCSzKuqO5M8DDgPWFFVl0/Yf+4uxZ6z4qeRHrBae2q/S5AkjZNkrKpGuunbze7p+6vqF0leAvxjVZ2U5IptK3FGWZ3kicAc4JTJAqMkSdKw6iY03pvkZcArgRc0bTP+5t7dqqqX97sGSZKkfuvmljvHAAcA766qG5MsBj7d27IkSZI0SFpDY1V9BzgBuCbJPsB/VNV7el6ZJEmSBkbr8nSS5cApwE107lv4mCSvqqrzeluaJEmSBkU31zT+A3BIVV0PkOQJwGeBZb0sbKZatmQxo6PuEJUkScOlm2sad9gcGAGq6nvMoo0wkiRJ6m6mcTTJx4DN02dHAWO9K0mSJEmDppvQ+IfAccDxdK5pPA/4cC+LkiRJ0mCZNDQm2Q94LPB/quoD01OSJEmSBs2E1zQmeQfweeBw4GtJXjdtVUmSJGmgTDbTeCSwtKruTrIL8HXgI9NTliRJkgbJZLun76mquwGq6ictfSVJkjTEJptpfGySrzbH2eI1VfXCnlYmSZKkgTFZaHzRFq/f38tCJEmSNLgmDI1V9a3pLGSqJNkZeHlVfbh5BOIJVfX8rfT7KPCB5tnaE431SeCsqvpSt5+/bsPNHLvmuAdeuKRpsWr5yn6XIEkz0jBep7gz8Edtnarqf08WGCVJkvRLwxga30Pn+ssrgb8H5iX5UpLrkpyWJABJ1iQZaY7vTPLuJFcluTjJ7lsOmuRvknwyyTD+ZpIkSZNqDUBJjuimbYC8Ffh+VS0F3gzsB/wJ8ERgT+AZWznn4cDFVfVkOk+8+ZV7UiZ5H7AbcExV3b/lyUlWJBlNMnrP+o1T+mUkSZIGQTezZn/RZdugurSq/qMJe1cCi7bS5+fAWc3x2BZ9/grYuaqOrara2gdU1eqqGqmqkTk7zZ26yiVJkgbEhBthkjwXOBT4rST/PO6tHYFf9LqwKbRp3PF9bP073zsuEG7Z5zJgWZJHVNVPe1SjJEnSQJvsljv/BYwCL6Qz+7bZBuBPe1nUNtoAzJ/C8b4OnE3nUYqHVNWGyTrvMX+huzMlSdLQmeyWO1cBVyU5rapmzMxiVf0kyQVJrgU2Aj+cgjG/mGQ+8NUkh1aVFy5KkqRZJRNcpkeSL1TV7ye5Bvi1TlW1b6+Lm4kyd5diz0P7XYY0I9XaU/tdgiTNKknGqmqkm76TLU//cfP/126MLUmSpNllsuXpW5v/66avHEmSJA2iyXZPb2Ary9KbVdWOPalIkiRJA2eymcb5AEneBfw3cCoQ4CimdneyJEmSBlw3N/f+X1X14araUFV3VNXJwOG9LkySJEmDY7KNMJvdl+Qo4HN0lqtfRucG2NqKZUsWMzrqDlBJkjRcuplpfDnw+3Tud/hD4IimTZIkSbNE60xjVd0EvKj3pUiSJGlQTbZ7+iQm3z19fE8qkiRJ0sCZbHl6lM4zp+cAvwPc0PwtxWsaJUmSZpXJbrlzCkCSVwPPrqp7m9f/AnxjWqqTJEnSQOhmI8yj+dX7Ms5r2iRJkjRLdHPLnfcAVyQ5t3n9LODEnlUkSZKkgdPN7ulPJPk/wFObprdW1X/3tixJkiQNktbl6SQBDgaeXFVnAg9N8pSeVyZJkqSB0c3y9IeB+4HnAO8CNgCnA/v3sK4HLcki4Kyq2qcfn79uw80cu+a4fny0pAdg1fKV/S5BkmaUbkLjU6vqd5JcAVBVtyd5aI/rkiRJ0gDpZvf0vUm2p7nRd5IFdGYeB16SPZNckeTNSb6c5OtJbkjyvnF9XpbkmiTXJnlv0/b7ST7QHP9xkh80x49N8u3+fBtJkqT+6SY0/jNwBrBbkncD3wb+v55WNQWS7EVnGf0Y4Md0bkp+JPAk4Mgkj0nyaOC9dJbelwL7JzkMOA84qBnqIOAnSX4LOBA4fyuftSLJaJLRe9Zv7PE3kyRJmn7d7J4+LckY8LtAgMOq6rs9r2zbLADOBA6vqrVJlgLfrKr1AEm+A+wB7AKsqaofN+2nAc+sqq8kmZdkPvAY4DPAM+kEyC9v+WFVtRpYDbBgr90mfPSiJEnSTDVpaEyyHXB1s6nkuukpaUqsB24BngGsbdo2jXv/PjrfPZOMcRGdWcrr6cwuvgY4APizqS5WkiRp0E0aGqvq/iRXJVlYVTdPV1FT4OfAYcDZSe6cpN8lwD8l2RW4HXgZcFLz3nl0dou/C7gCeDawcfNs5UT2mL/QXZmSJGnodLN7+lHA2iSXAndtbqyqF/asqilQVXcleT7w78CnJ+hza5K/AM6lM+v4b829KKEzu/gY4Lyqui/JLcys2VZJkqQpk6rJL8FL8qyttVfVt3pS0QyXubsUex7a7zKkKVVrT+13CZKkHkgyVlUj3fTtZiPMt5I8EngKndvuXOZjBCVJkmaXbh4j+L+BS4GXAC8FLk7yml4XJkmSpMHRzTWNbwb2q6qfACTZBbgQ+HgvC5MkSdLg6Obm3v9B53nTm22gczsbSZIkzRITzjQmeVNz+J/AJUnOpHNN44voLFdLkiRplphseXp+8//7zd9mZ26lrxrLlixmdNSdppIkabhMGBqr6p3TWYgkSZIGV+tGmCTn0lmW/hVV9ZyeVCRJkqSB083u6RPGHc8BDgd+0ZtyJEmSNIi6ubn32BZNFyTxaTCSJEmzSDfL048Y93I7YBnwyJ5VJEmSpIHTzfL0GJ1rGkNnWfpG4LW9LEqSJEmDpZvl6cXTUYgkSZIG14RPhEmyf5JHjnv9yiRnJvnnLZasJUmSNOQme4zgKuDnAEmeCbwH+BSwHljd+9IkSZI0KCZbnt6+qn7aHB8JrK6q04HTk1zZ+9JmpnUbbubYNcf1uwxpRli1fGW/S5AkdWmymcbtk2wOlb8LnDPuvW420EiSJGlITBYaPwt8K8mZwEbgfIAkj6OzRD0jJXlTkmubvz9JsijJd5N8JMnaJN9IMrfp+9gkX08yluT8JHv3u35JkqR+mDA0VtW7gT8DPgkcWFU17pw39r60qZdkGXAM8FTgacDrgN8EHg+srKolwM/oPPUGOtduvrGqltF5Ms6HJxh3RZLRJKP3rN/Y428hSZI0/SZdZq6qi7fS9r3eldNzBwJnVNVdAEm+DBwE3FhVm6/THAMWJZkHPB34YpLN5//G1gatqtU0m4MW7LXbrz2nW5IkaaabbdcmZoL2TeOO7wPm0plR/VlVLe15VZIkSQNutoXG84BPJnkPnQD5YuBoYMWWHavqjiQ3Jjmiqr6YznTjvlV11WQfsMf8he4IlSRJQ2eyjTBDp6oup3ON5qXAJcBHgdsnOeUo4LVJrgLWAi/qdY2SJEmDKL/c3zJBh+QlwHuB3ejMzgWoqtqx9+XNPJm7S7Hnof0uQ9omtfbUfpcgSZoGScaqaqSbvt0sT78PeEFVfXfbypIkSdJM1c3y9A8NjJIkSbNbNzONo0k+D3yFcbuMq+rLPatKkiRJA6Wb0LgjcDdwyLi2AgyNkiRJs0RraKyqY6ajEEmSJA2uCUNjkrdU1fuSnERnZvFXVNXxPa1shlq2ZDGjo+48lSRJw2WymcbNm19Gp6MQSZIkDa4JQ2NV/Wvz/5TpK0eSJEmDaFY9EUaSJEkPjqFRkiRJrQyNkiRJatUaGpO8L8mOSXZI8s0ktyV5xXQUJ0mSpMHQzUzjIVV1B/B84D+AJwBv7mlVkiRJGijdhMYdmv+HAp+tqp/2sB5JkiQNoG5C478muQ4YAb6ZZAFwT2/Lmn5JFiW5tt91SJIkDaJuHiP41iTvBe6oqvuS3A28qPelzUzrNtzMsWuO63cZ0oy0avnKfpcgSZrAZI8RfMlW2sa//HIvCuqz7ZN8BHg68J90wvErgBXAQ4H/Hzi6qu7uX4mSJEnTb7Ll6Rc0f68FPgYc1fx9lE6QGkaPB1ZW1RLgZ8DhwJerav+qejKdRyu+tp8FSpIk9cNkjxE8BiDJWcATq+rW5vWjgGFdQ7qxqq5sjseARcA+Sf4W2BmYB5y95UlJVtCZjWTe7vOmp1JJkqRp1M1GmEWbA2Pjh3RuuzOMNo07vo9OqP4k8IaqehLwTmDOlidV1eqqGqmqkTk7zZ2WQiVJkqZT60YYYE2Ss4HPAgX8AXBuT6saLPOBW5PsQGd5/j/7XI8kSdK062b39BuSvBh4ZtO0uqrO6G1ZA+WvgEuAdcA1dELkhPaYv9AdoJIkaehMGhqTbA+cXVUHA0MdFKvqJmCfca/fP+7tk6e9IEmSpAEyaWjcfF/GJDtV1frpKmomG1t7I1lydL/L0BCptaf2uwRJkrq6pvEe4Jok/w7ctbmxqo7vWVWSJEkaKN2Exq81f5IkSZqlutkIc0qSh/LL2+xcX1X39rYsSZIkDZLW0JhkOXAKcBMQ4DFJXlVV5/W2NEmSJA2Kbpan/wE4pKquB0jyBDr3bFzWy8IkSZI0OLoJjTtsDowAVfW95kbX2oplSxYzOupuV0mSNFy6CY2jST4GbE5CR9F5LrMkSZJmiW5C4x8CxwHH07mm8Tzgw70sSpIkSYNlwtCY5DDgwqr6EfCB5k+SJEmz0HaTvPcK4IokNyT5ZJIVSZZMV2GSJEkaHBOGxqp6aVX9FvA/gW8A+wKfSvLjJP82XQVKkiSp/7q5ufdNSeYAc5u/zceSJEmaJSa7pvFtwAHAAuB64GLgQ8CKqrpvesqTJEnSIJhspvGVwJ3AWcCFwCVVtX5aqpIkSdJAmeyaxr2BQ4BRYDlwRpJLk3wkyTHTVN+USPKuJAf3uw5JkqSZKlXV3il5CJ3HBj4TOBZYXFXb97i2KZFk++lcTl+w1271klVHTNfHSVNu1fKV/S5BkjRNkoxV1Ug3fSecaUzywiTvSXI+8CPg/cCuwJ8Bj5ySSrdRkkVJrktySpKrk3wpycOS3JTkHUm+DRzR3DLopc05NyV5Z5LLk1yTZO+mfV6STzRtVyc5vGk/JMlFTf8vJpnXx68sSZLA7gaSAAAgAElEQVTUF5Pdp/HVwG3AW4BHVtVBVfXnVXVmVf14Wqrrzl7A6qraF7gD+KOm/Z6qOrCqPreVc26rqt8BTgZOaNr+ClhfVU9qxjonya7A24GDm/6jwJt6+WUkSZIG0YQbYarqJdNZyDa4paouaI4/TedxhwCfn+ScLzf/x4DN3/Ng4A82d6iq25M8H3gicEESgIcCF205WJIVwAqAebs7ESlJkoZPN8+eHnRbXpS5+fVdk5yzqfl/H7/8DbKVsQL8e1W9bNICqlYDq6FzTWNbwZIkSTPNZMvTM8XCJAc0xy8Dvv0gx/kG8IbNL5L8Jp17Uz4jyeOatoclecK2FCtJkjQTTTrTmGR74JSqesU01fNgfBd4VZJVwA10rlN844MY52+BlUmupTMD+c6q+nKSVwOfTfIbTb+3A9+baJA95i9096kkSRo6k4bGqrovyYIkD62qn09XUQ/Q/VX1+i3aFo1/UVWvHne8aNzx5ntQUlV3Aq/acvCqOgfYf6qKlSRJmom6uabxJjobQb7KuOsEq+oDvSpqJhtbeyNZcnS/y5AesFp7ar9LkCQNsG5C4381f9sB83tbzgNTVTcB+/S7DkmSpGHXGhqr6p3TUYgkSZIGV2toTLKAzg2+lwBzNrdX1XN6WJckSZIGSDe33DkNuA5YDLyTzjWOl/WwJkmSJA2YbkLjLlX1MeDeqvpWVb0GeFqP65IkSdIA6WYjzL3N/1uTPI/Oppj/0buSZrZlSxYzOuouVEmSNFy6CY1/m2Qn4M+Ak4AdgT/taVWSJEkaKN3snj6rOVwPPLu35UiSJGkQTRgak5wE1ETvV9XxPalIkiRJA2eymcbRaatCkiRJA23C0FhVp0xnIZIkSRpc3dzc+1y2skztzb0lSZJmj252T58w7ngOcDjwi96UI0mSpEHUze7psS2aLkjyrR7VI0mSpAHUzfL0I8a93A5YBjyyZxX1UJITgTur6v0P8LylwKOr6t96UpgkSdKA62Z5eozONY2hsyx9I/DaXhY1gJYCI0BraFy34WaOXXNc7yuShsCq5Sv7XYIkqUvdLE8vno5CeiXJXwKvBG4BfgyMNTOH/wI8DPg+8Jqquj3JGuASOjcx35lOOL4EeBcwN8mBwN9V1een/YtIkiT10XZtHZLMSfKmJF9OcnqSP00yZzqK21ZJlgF/AOwHvATYv3nrU8CfV9W+wDXAX4877SFV9RTgT4C/rqqfA+8APl9VSw2MkiRpNmoNjXQC1hI6z53+EPDbwKm9LGoKHQScUVV3V9UdwFeBhwM7V9XmzTynAM8cd86Xm/9jwKJuPiTJiiSjSUbvWb9xaiqXJEkaIN1c07hXVT153Otzk1zVq4J6YMJHIU5gU/P/Prr7faiq1cBqgAV77fZAP0+SJGngdTPTeEWSp21+keSpwAW9K2lKnQe8OMncJPOBFwB3AbcnOajpczTQdguhDcD83pUpSZI02LqZSXsq8MokNzevFwLfTXINUM11gQOpqi5P8nngSmAdcH7z1quAf0nyMOAHwDEtQ50LvDXJlbRshNlj/kJ3hEqSpKGTqslXU5PsMdn7VbVuSiua4UZGRmp0dLTfZUiSJLVKMlZVI131bQuNzYBPprOpBOD8qppJ1zROq8zdpdjz0H6XoQFQa2fKfjFJ0mz1QEJjN7fc+WPgNGC35u/TSd64bSVKkiRpJunmmsbXAk+tqrsAkrwXuIjOLXgkSZI0C3Szezp0bj+z2X1NmyRJkmaJbmYaPwFckuSM5vVhwMd6V5IkSZIGTTfPnv5A80zmA+nMMB5TVVf0ujBJkiQNjglDY/N86dcDj6PzfOYPV9UvpquwmWrZksWMjrprVpIkDZfJrmk8BRihExifC7x/WiqSJEnSwJlsefqJVfUkgCQfAy6dnpIkSZI0aCababx384HL0pIkSbPbZDONT05yR3McYG7zOnSeOb1jz6uTJEnSQJgwNFbV9tNZiCRJkgZXNzf3liRJ0ixnaJQkSVIrQ6MkSZJaGRonkeTVST7U7zokSZL6rZtnTw+9JNtX1X1TMda6DTdz7JrjpmIoaZutWr6y3yVIkobEwMw0JlmU5LokH01ybZLTkhyc5IIkNyR5SpJHJPlKkquTXJxk3+bcE5N8PMmaJD9Icvy4cb+SZCzJ2iQrxrXfmeRdSS4BDkiyf5ILk1yV5NIk85uuj07y9aaG903vryJJkjQYBm2m8XHAEcAK4DLg5cCBwAuBtwG3AFdU1WFJngN8CljanLs38GxgPnB9kpOr6l7gNVX10yRzgcuSnF5VPwEeDlxbVe9I8lDgOuDIqrosyY7AxmbcpcB+wKZm3JOq6pZe/xCSJEmDZGBmGhs3VtU1VXU/sBb4ZlUVnedfL6ITIE8FqKpzgF2S7NSc+7Wq2lRVtwE/AnZv2o9PchVwMfAY4PFN+33A6c3xXsCtVXVZM/Yd456C882qWl9V9wDfAfbYsugkK5KMJhm9Z/3GLd+WJEma8QYtNG4ad3z/uNf305kVzVbOqa2cex/wkCTLgYOBA6rqycAVwJymzz3jrmPMuHEmq+k+tjI7W1Wrq2qkqkbm7DR3gmEkSZJmrkELjW3OA44CaALhbVV1xyT9dwJur6q7k+wNPG2CftfRuXZx/2bs+UkGbelekiSpb2ZaMDoR+ESSq4G7gVe19P868Pqm//V0lqh/TVX9PMmRwEnNtY8b6cxQPmB7zF/ojlVJkjR00rlkUFNlZGSkRkdH+12GJElSqyRjVTXSVV9D49TK3F2KPQ/tdxkaIrX21H6XIEkaUg8kNM60axolSZLUB4ZGSZIktTI0SpIkqZWhUZIkSa0MjZIkSWo10+7TOPCWLVnM6Ki7XSVJ0nBxplGSJEmtDI2SJElqZWiUJElSK0OjJEmSWhkaJUmS1MrQKEmSpFaGRkmSJLUyNEqSJKmVoXErkrw6yYf6XYckSdKg8IkwU2zdhps5ds1x/S5Ds8iq5Sv7XYIkaRaYkTONSRYluS7JKUmuTvKlJA9LsizJt5KMJTk7yaOa/kuTXNz0PSPJbzbta5L8Y5ILk1yb5Clb+awFSU5Pclnz94zp/r6SJEn9NiNDY2MvYHVV7QvcARwHnAS8tKqWAR8H3t30/RTw503fa4C/HjfOw6vq6cAfNeds6Z+AD1bV/sDhwEd78WUkSZIG2Uxenr6lqi5ojj8NvA3YB/j3JADbA7cm2QnYuaq+1fQ9BfjiuHE+C1BV5yXZMcnOW3zOwcATmzEBdkwyv6o2bG5IsgJYATBv93lT9f0kSZIGxkwOjbXF6w3A2qo6YHxjExofyDhbvt4OOKCqNk44QNVqYDXAgr122/J8SZKkGW8mL08vTLI5IL4MuBhYsLktyQ5JllTVeuD2JAc1fY8GvjVunCOb/gcC65v+430DeMPmF0mWTv1XkSRJGmwzeabxu8CrkqwCbqBzPePZwD83s4sPAf4RWAu8CviXJA8DfgAcM26c25NcCOwIvGYrn3M8sDLJ1c2Y5wGvn6ioPeYvdDerJEkaOqmaeaupSRYBZ1XVPts4zhrghKoanYKyABgZGanR0SkbTpIkqWeSjFXVSDd9Z/JM40AaW3sjWXJ0v8vQLFJrT+13CZKkWWBGhsaquonOTultHWf5NhcjSZI0C8zkjTCSJEmaJoZGSZIktTI0SpIkqZWhUZIkSa1m5EaYQbZsyWJGR93NKkmShoszjZIkSWplaJQkSVIrQ6MkSZJaGRolSZLUytAoSZKkVoZGSZIktTI0SpIkqZWhUZIkSa0MjV1IcliSJ/a7DkmSpH7xiTDdOQw4C/hOW8d1G27m2DXH9b4iDZVVy1f2uwRJkiY1a0Njkr8CjgJuAW4DxoAzgJXAAuBu4HXAI4AXAs9K8nbg8Kr6fl+KliRJ6pNZGRqTjACHA/vR+Q0upxMaVwOvr6obkjwV+HBVPSfJV4GzqupLfStakiSpj2ZlaAQOBM6sqo0ASf4VmAM8Hfhiks39fqObwZKsAFYAzNt93pQXK0mS1G+zNTRmK23bAT+rqqUPdLCqWk1nlpIFe+1W21ibJEnSwJmtu6e/DbwgyZwk84Dn0bmG8cYkRwCk48lN/w3A/P6UKkmS1H+pmp0TY0lOBF4GrAN+DKwB/i9wMvAoYAfgc1X1riTPAD4CbAJeOtlGmJGRkRodHe1t8ZIkSVMgyVhVjXTTd7YuTwO8v6pOTPIw4DzgH6rqRuD3tuxYVRcA3qdRkiTNWrM5NK5ubtg9Bzilqi6fikHH1t5Ilhw9FUNpFqu1p/a7BEmSfsWsDY1V9fJ+1yBJkjRTzNaNMJIkSXoADI2SJElqZWiUJElSK0OjJEmSWs3ajTC9smzJYkZH3fkqSZKGizONkiRJamVolCRJUitDoyRJkloZGiVJktTK0ChJkqRWhkZJkiS1MjRKkiSplaFRkiRJrQyND0CSm5Ls2u86JEmSptvQPxEmSYBU1f3T8XnrNtzMsWuOm46P0gyxavnKfpcgSdI2G8qZxiSLknw3yYeBy4Gjk1yT5Nok7236vDbJB8ed87okH2iOv5JkLMnaJCv68y0kSZIGx1CGxsZewKeA5wF/AzwHWArsn+Qw4HPAC5Ps0PQ/BvhEc/yaqloGjADHJ9llWiuXJEkaMMMcGtdV1cXA/sCaqvpxVf0COA14ZlXdBZwDPD/J3sAOVXVNc+7xSa4CLgYeAzx+sg9KsiLJaJLRe9Zv7NkXkiRJ6pdhvqbxruZ/JunzUeBtwHU0s4xJlgMHAwdU1d1J1gBzJvugqloNrAZYsNdutU1VS5IkDaBhnmnc7BLgWUl2TbI98DLgWwBVdQmdmcSXA59t+u8E3N4Exr2Bp/WhZkmSpIEyzDONAFTVrUn+AjiXzqzjv1XVmeO6fAFYWlW3N6+/Drw+ydXA9XSWqLu2x/yF7paVJElDZyhDY1XdBOwz7vVngM9M0P1A4IPj+m4CnjvBuIumrEhJkqQZZChDYzeS7AxcClxVVd+cqnHH1t5Ilhw9VcNJrWrtqf0uQZI0C8za0FhVPwOe0O86JEmSZoLZsBFGkiRJ28jQKEmSpFaGRkmSJLUyNEqSJKnVrN0I0yvLlixmdNTdrJIkabg40yhJkqRWhkZJkiS1MjRKkiSplaFRkiRJrQyNkiRJamVolCRJUitDoyRJkloZGiVJktRqqENjkp2T/FFz/OgkX+p3TZIkSTNRqqrfNfRMkkXAWVW1z3R95oK9dquXrDpiuj5Os9iq5Sv7XYIkaYZLMlZVI930HfbHCL4HeGySK4EbgN+uqn2SvBo4DNge2Af4B+ChwNHAJuDQqvppkscCK4EFwN3A66rquun/GpIkSf011MvTwFuB71fVUuDNW7y3D/By4CnAu4G7q2o/4CLglU2f1cAbq2oZcALw4WmpWpIkacAM+0zjZM6tqg3AhiTrgX9t2q8B9k0yD3g68MUkm8/5ja0NlGQFsAJg3u7zelq0JElSP8zm0Lhp3PH9417fT+d32Q74WTNLOamqWk1nVpIFe+02vBeJSpKkWWvYl6c3APMfzIlVdQdwY5IjANLx5KksTpIkaaYY6pnGqvpJkguSXAt890EMcRRwcpK3AzsAnwOumuyEPeYvdFerJEkaOkN9y51+GBkZqdHR0X6XIUmS1OqB3HLH0DjFMneXYs9D+12GpkmtPbXfJUiS9KA9kNA47Nc0SpIkaQoYGiVJktTK0ChJkqRWhkZJkiS1MjRKkiSp1VDfp7Efli1ZzOioO2olSdJwcaZRkiRJrQyNkiRJamVolCRJUitDoyRJkloZGiVJktTK0ChJkqRWhkZJkiS1MjRKkiSp1awKjUleneRDE7z3b0l2nuTcP0nysN5VJ0mSNLiG8okwSbavqvseyDlVdWhLlz8BPg3cPVmndRtu5tg1xz2Qj5a6tmr5yn6XIEmapXo205hkUZLrknw0ybVJTktycJILktyQ5ClJHpHkK0muTnJxkn2bc09M8vEka5L8IMnx48b9SpKxJGuTrBjXfmeSdyW5BDggyf5JLkxyVZJLk8xvuj46ydebGt437vybkuya5OFJvtacd22SI5vPfzRwbpJze/WbSZIkDapezzQ+DjgCWAFcBrwcOBB4IfA24Bbgiqo6LMlzgE8BS5tz9waeDcwHrk9yclXdC7ymqn6aZC5wWZLTq+onwMOBa6vqHUkeClwHHFlVlyXZEdjYjLsU2A/Y1Ix7UlXdMq7m3wP+q6qeB5Bkp6pan+RNwLOr6rYe/E6SJEkDrdfXNN5YVddU1f3AWuCbVVXANcAiOgHyVICqOgfYJclOzblfq6pNTUj7EbB70358kqv4f+3de3RW9Z3v8ffnAJJw1QGdqeAQqNwEAxQIYNVFAWdQqWWOVuQ4SNHO2K7iKI5H22OHYtcse5HOtLTOKN6A1gJTL+dQXFaFltGqXAJyUxBthRKlVGmJFAnX7/ljb2IMSZ6AD+yH8Hmtxcrz7P3bv/3dvyQP33z35QdLgXOA7unyg8Dj6euewLaIWJH2/X5EHEjXLY6IyoioAl4DutSKeR0wStJ3JF0UEZW5DlLSP0oql1ReVbknV3MzMzOzk87xThr31nh9qMb7QyRVTtWxTdSx7UGguaThwChgWET0A14BitI2VTWuY1SNfhqK6SC1qq0RsQkYSJI8fkvS1Hr6qbnNzIgYFBGDitoX52puZmZmdtLJ+u7p54FrAdKE8L2IeL+B9u2BP0XEB5J6AUPrabeR5NrFwWnfbSU16lS8pLOBDyLiJ8B04FPpql0kp8rNzMzMTjlZ3z09DXhE0lqSu5In5mj/C+BLafvXSU5RHyEi9kkaB/wwvfZxD0mFsjHOB+6RdAjYD3w5XT4TeFrStoj4TH0bd2n7177D1czMzJocJZcYWr4MGjQoysvLsw7DzMzMLCdJKyNiUKPaOmnMLxV3CLrleuSjnazi1R9nHYKZmVneHE3SmPU1jWZmZmZ2EnDSaGZmZmY5OWk0MzMzs5ycNJqZmZlZTk4azczMzCynrJ/T2OQM7NOV8nLfYWtmZmZNiyuNZmZmZpaTk0YzMzMzy8lJo5mZmZnl5KTRzMzMzHJy0mhmZmZmOTlpNDMzM7OcnDSamZmZWU5OGs3MzMwsJyeNKUmzJF2Vvl4iaVDWMZmZmZkViiY5I4wkAYqIQyd631t2/Y4bl3zlRO/WrNHuH35v1iGYmdlJqMkkjZJKgKeBXwHDgO9L+hLQEvgNMCki/ixpKvBZoBh4CbgxIqKePm8A+kbElPT9PwC9I+LW43w4ZmZmp7T9+/dTUVFBVVVV1qE0CUVFRXTu3JkWLVoccx9NJmlM9QQmAVOBJ4BREbFb0h3ArcA3gR9FxDcBJP0YGAP8vJ7+5gFrJd0eEfvTvm88zsdgZmZ2yquoqKBt27aUlJSQnEC0YxUR7Nixg4qKCrp27XrM/TS1axq3RMRSYChwHvCipNXARKBL2uYzkpZJWgeMAPrU11lE7AZ+CYyR1AtoERHrareT9I+SyiWVV1XuyfMhmZmZnXqqqqro0KGDE8Y8kESHDh0+dtW2qVUad6dfBTwXEeNrrpRUBPwHMCgitkqaBhTl6PNB4P8AG4FH6moQETOBmQBn9jyrzlPdZmZmdnScMOZPPsayqVUaD1sKfFrSuQCSWknqwYcJ4nuS2gBX5eooIpYB5wD/C5h7nOI1MzOzAtOsWTP69+9P3759+exnP8vOnTtP6P7btGlzQveXS1OrNAIQEe9K+gIwV1LLdPHXI2KTpAeAdcBmYEUju/wvoH9E/ClXwy5t/9p3p5qZmeVZvp9M0pj/q4uLi1m9ejUAEydO5N577+XOO+/MaxwnkyZTaYyIzRHRt8b7X0bE4IgoTf8tSJd/PSLOjYhRETEpIqaly78QEY+lr4dHRHmN7i8EHjiBh2NmZmYFZNiwYbz99tsALFmyhDFjxlSvmzx5MrNmzQKgpKSEO+64g7KyMsrKynjzzTcB+PnPf86QIUMYMGAAo0aNYvv27QBMmzaN6dOnV/fVt29fNm/efGIO6ig1yUpjvkg6HVgOrImIxY3ZZuWrb6E+E45vYFanePXHWYdgZmZN0MGDB1m8eDE33HBDo9q3a9eO5cuXM2fOHG655RYWLlzIhRdeyNKlS5HEgw8+yHe/+12+973vHefI88tJYwMiYifQI+s4zMzM7MTbs2cP/fv3Z/PmzQwcOJBLLrmkUduNHz+++uuUKVOA5BFC48aNY9u2bezbt+9jPfomK03m9LSZmZlZPh2+pnHLli3s27ePe+9NroNs3rw5hw59OOlc7UfZ1LxT+fDrm266icmTJ7Nu3Truv//+6m1y9VVInDSamZmZNaB9+/bMmDGD6dOns3//frp06cJrr73G3r17qaysZPHij17BNn/+/Oqvw4YNA6CyspJOnToBMHv27Oq2JSUlrFq1CoBVq1bx1ltvnYhDOiY+PW1mZmaWw4ABA+jXrx/z5s1jwoQJXH311ZSWltK9e3cGDBjwkbZ79+5lyJAhHDp0iLlzk6f1TZs2jc9//vN06tSJoUOHVieHV155JXPmzKF///4MHjyYHj0K96o41TPtsh0jFXcIul2WdRinJN8IY2bWdGzYsIHevXtnHcZRKykpoby8nI4dO2YdyhHqGlNJKyNiUGO2d6Uxzwb26Up5uZMXMzMza1qcNJqZmZnlSaE+YzEffCOMmZmZmeXkpNHMzMzMcnLSaGZmZmY5OWk0MzMzs5ycNJqZmZnVQRITJkyofn/gwAHOPPNMxowZk0k8s2bNYvLkyZnsG3z3tJmZmZ0E1GdC7kZHoTHP9m3dujXr169nz549FBcX89xzz1XP6nI8HTx4kGbNmh33/RwtVxrNzMzM6nHppZfy1FNPATB37lzGjx9fve6Pf/wjY8eOpbS0lKFDh7J27Vogmf3l+uuvZ/jw4XTr1o0ZM2ZUbzN27FgGDhxInz59mDlzZvXyNm3aMHXqVIYMGcLLL7/MihUruOCCC+jXrx9lZWXs2rULgHfeeYfRo0fTvXt3br/9dgAeeughpkyZUt3XAw88wK233pr3sXDSaGZmZlaPa665hnnz5lFVVcXatWsZMmRI9bpvfOMbDBgwgLVr13L33Xdz3XXXVa/buHEjzzzzDMuXL+euu+5i//79ADz88MOsXLmS8vJyZsyYwY4dOwDYvXs3ffv2ZdmyZZSVlTFu3Dh+8IMfsGbNGhYtWkRxcTEAq1evZv78+axbt4758+ezdetWrrnmGhYsWFC9j0ceeYRJkyblfSycNJqZmZnVo7S0lM2bNzN37lwuu+yj0wT/+te/rr7mccSIEezYsYPKykoALr/8clq2bEnHjh0566yz2L59OwAzZsygX79+DB06lK1bt/LGG28A0KxZM6688koAXn/9dT7xiU8wePBgANq1a0fz5skVhSNHjqR9+/YUFRVx3nnnsWXLFlq3bs2IESNYuHAhGzduZP/+/Zx//vl5Hwtf02hmZmbWgCuuuILbbruNJUuWVFcGASLiiLaSAGjZsmX1smbNmnHgwAGWLFnCokWLePnll2nVqhXDhw+nqqoKgKKiourrGCOiup/a6uoX4Itf/CJ33303vXr1Oi5VRnCl0czMzKxB119/PVOnTj2ienfxxRfz6KOPArBkyRI6duxIu3bt6u2nsrKSM844g1atWrFx40aWLl1aZ7tevXrxzjvvsGLFCgB27dpVnRzWZ8iQIWzdupWf/vSnH7nuMp9caTQzMzNrQOfOnbn55puPWD5t2jQmTZpEaWkprVq1Yvbs2Q32M3r0aO677z5KS0vp2bMnQ4cOrbPdaaedxvz587npppuq79xetGhRzjivvvpqVq9ezRlnnNG4AztKqqu0asdu0KBBUV5ennUYZmZmJ7UNGzbQu3fvrMM4qYwZM4YpU6YwcuTIOtfXNaaSVkbEoMb079PTZmZmZiexnTt30qNHD4qLi+tNGPPBp6fNzMzMTmKnn346mzZtOu77caXRzMzMzHJy0mhmZmYFyfdd5E8+xtJJo5mZmRWcoqIiduzY4cQxDyKCHTt2UFRU9LH68TWNZmZmVnA6d+5MRUUF7777btahNAlFRUV07tz5Y/XhpNHMzMwKTosWLejatWvWYVgNPj1tZmZmZjk5aTQzMzOznJw0mpmZmVlOnkYwzyTtAl7POo4C1xF4L+sgCpjHJzePUcM8Prl5jBrm8cmtqYxRl4g4szENfSNM/r3e2DkcT1WSyj1G9fP45OYxapjHJzePUcM8PrmdimPk09NmZmZmlpOTRjMzMzPLyUlj/s3MOoCTgMeoYR6f3DxGDfP45OYxapjHJ7dTbox8I4yZmZmZ5eRKo5mZmZnl5KQxjySNlvS6pDclfTXreAqJpHMk/UrSBkmvSro565gKlaRmkl6RtDDrWAqNpNMlPSZpY/qzNCzrmAqNpCnp79h6SXMlFWUdU9YkPSzpD5LW11j2F5Kek/RG+vWMLGPMUj3jc0/6e7ZW0pOSTs8yxqzVNUY11t0mKSR1zCK2E8lJY55IagbcC1wKnAeMl3RetlEVlAPAP0dEb2Ao8BWPT71uBjZkHUSB+gHwi4joBfTD4/QRkjoB/wQMioi+QDPgmmyjKgizgNG1ln0VWBwR3YHF6ftT1SyOHJ/ngL4RUQpsAr52ooMqMLM4coyQdA5wCfC7Ex1QFpw05k8Z8GZE/DYi9gHzgM9lHFPBiIhtEbEqfb2L5D/7TtlGVXgkdQYuBx7MOpZCI6kdcDHwEEBE7IuIndlGVZCaA8WSmgOtgHcyjidzEfE88Mdaiz8HzE5fzwbGntCgCkhd4xMRz0bEgfTtUqDzCQ+sgNTzMwTw78DtwClxg4iTxvzpBGyt8b4CJ0V1klQCDACWZRtJQfo+yQfQoawDKUDdgHeBR9LT9w9Kap11UIUkIt4GppNUPbYBlRHxbLZRFay/jIhtkPxRC5yVcTyF7Hrg6eEqNQcAAAieSURBVKyDKDSSrgDejog1WcdyojhpzB/VseyU+MvjaEhqAzwO3BIR72cdTyGRNAb4Q0SszDqWAtUc+BTwnxExANjNqX1K8QjpdXmfA7oCZwOtJf19tlHZyUzSnSSXFz2adSyFRFIr4E5gataxnEhOGvOnAjinxvvO+LTQR0hqQZIwPhoRT2QdTwH6NHCFpM0klzeMkPSTbEMqKBVARUQcrlA/RpJE2odGAW9FxLsRsR94Argg45gK1XZJnwBIv/4h43gKjqSJwBjg2vDz+Wr7JMkfZ2vSz+zOwCpJf5VpVMeZk8b8WQF0l9RV0mkkF58vyDimgiFJJNeibYiIf8s6nkIUEV+LiM4RUULy8/PLiHCVKBURvwe2SuqZLhoJvJZhSIXod8BQSa3S37mR+Gah+iwAJqavJwL/L8NYCo6k0cAdwBUR8UHW8RSaiFgXEWdFREn6mV0BfCr9nGqynDTmSXrB8GTgGZIP6f+KiFezjaqgfBqYQFI9W53+uyzroOykcxPwqKS1QH/g7ozjKShpFfYxYBWwjuQz/pSbtaI2SXOBl4Gekiok3QB8G7hE0hskd79+O8sYs1TP+PwIaAs8l35e35dpkBmrZ4xOOZ4RxszMzMxycqXRzMzMzHJy0mhmZmZmOTlpNDMzM7OcnDSamZmZWU5OGs3MzMwsJyeNZpZXkg6mj+hYL+ln6cwJWcRxy9HuW9JFkl5N4y+ute5jH9exxJSjvyskfTV9PVbSeTXWLZE0KMf2JZL2pMf1mqT7JOX1/wVJ0yTd9jG2f0VS//R1c0m7a85yI2mlpGN+yHtjxsnMEk4azSzf9kRE/4joC+wDvtTYDSU1y2MctwBHm6BdC0xP499Ta90xH9fHjKleEbEgIg4/X3AscF5D7evxm4joD5Sm24/NV3zHQlLzWote4sNZbfoBrx9+n8493g1o1Ny/dfRtZkfBSaOZHU8vAOcCSPp7ScvTqtb9hxNESX+W9E1Jy4BhkgZLeknSmrR9W0nNJN0jaYWktZJuTLcdnlaKHpO0UdKjSvwTydzLv5L0q9pBSRqZVrDWSXpYUktJXwSuBqZKyjXPbs3jujWtPq6XdEu6rLWkp9JjWC9pXO2Y0mOala5fJ2lKrRibSfptejynSzok6eJ03QuSzpX0BUk/knQBcAVwTzq+n0y7+Xw6hpskXdTQAaUTFLwEnJvu854asY2rMd7PS3qydmVS0p9rxH6VpFl1jPs/pN/DNZIeP1x1Tcfh39Lv1XdqbfYiHyaNFwD3kTzYHaAMWBURByX9haT/m/58LJVUmvY9TdJMSc8CcyQVS5qXtpsPFGNmjeK/uszsuEirOpcCv5DUGxgHfDoi9kv6D5Kq3hygNbA+IqYqmYJzIzAuIlZIagfsAW4AKiNisKSWwItpEgAwAOhDMtf7i+k+Zki6FfhMRLxXK64iYBYwMiI2SZoDfDkivi/pQmBhRDzWyOMaCEwChgAClkn6b5Lq1zsRcXm6TfuIqKwZU7ptp7RyiaTTa+4nTYQ2kVT/ugIrgYvS5LpzRLyZxktEvCRpQc3YJQE0j4gyJbMvfYNkbur6jqsVybSDU4H/SZKY9QM6AiskPZ82LUtj2gL8Im1b73jV8kREPJDu719Jvq8/TNf1AEZFxMFa27wE/Gv6+gLgLmC8pLbp+xfTdXcBr0TEWEkjSH62DieXA4ELI2JP+j34ICJK08RyVSNjNzvludJoZvlWLGk1UE4yF/JDJMnIQJLkY3X6vlva/iDwePq6J7AtIlYARMT7aQXsb4Dr0m2XAR2A7uk2yyOiIiIOAauBkhzx9QTeiohN6fvZwMXHeFwXAk9GxO6I+DPwBHARyRR+oyR9R9JFEVFZR3+/BbpJ+qGSeX7fr6PNC2lsFwPfSvc3mGSu+8Z4Iv26kvrH5ZPpcb0IPBURT6f7mRsRByNiO/Df6X4hGe/fpsnd3LRtY/VNq6TrSP5o6FNj3c/qSBiJiM3AaZL+CuhFcnp6BUmifgFJUkkax4/TbX4JdJDUPl23oMblBhcDP0nbrQXWHkX8Zqc0VxrNLN/2pNfIVVNS9podEV+ro31VjWRBQF1zmwq4KSKeqdXvcGBvjUUHyf25phzr61PfcR0hrWAOBC4DviXp2Yj4Zq02f5LUD/hb4Cskp8avr9XVCyTXTp5NUgH838Bw4Hka5/DYNDQuv6l9XDQ8RrW/P1HH8qJ6tp0FjI2INZK+QHIsh+1uYJ8vA1eR/EERkpaSzGdfBixtIObDMdXu2/Pnmh0DVxrN7ERYDFwl6SyA9PqzLnW02wicLWlw2q5tejr4GeDLklqky3souQmiIbuAtvXso0TSuen7CSSVtGPxPDBWUqs0nr8DXpB0Nskp0J8A04HDd/dWxySpI/A/IuJx4F9qtKlpGUk17VBEVJFUUm8kSSZrq+94j/W4xqXXVZ5JUp1bnq4rk9Q1vZZxHPDrdPl2Sb3T5X9XT79tgW3p9/Hao4jnRWAKSfJI+vU64PcRsbNGzNdC9R8T70VEXdXbmu36ktwAZGaN4EqjmR13EfGapK8Dz6ZJxX6S6tqWWu32pTdd/FDJI2/2kFyH9yDJ6dVVaXXvXXLf5TsTeFrStoj4TI19VEmaBPwsTUhXkNxccSzHtSq94eNwQvVgRLwi6W9Jbko5lB7rl2vHRHIn9SP68BE3R1RhI2KvpK18WE17ARhPcvq7tnnAA0puuLnqWI6nhieBYSR3JQdwe0T8XlIvkoTt28D5JAnYk+k2XwUWAluB9UCbOvr9F5JEeEt6DI1Ncl8E/j3dNxGxTcmNVC/VaDONZDzXAh8AE+vp6z9rtFvNh987M8tBEa7Sm5lZbmkF77aIGJN1LGZ24vn0tJmZmZnl5EqjmZmZmeXkSqOZmZmZ5eSk0czMzMxyctJoZmZmZjk5aTQzMzOznJw0mpmZmVlOThrNzMzMLKf/D4PhmRJecYdcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a21b83908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(X_tr_f)\n",
    "eda = cv.transform(X_tr_f)\n",
    "eda_set = pd.DataFrame(eda.todense(), columns = cv.get_feature_names())\n",
    "eda_set['ru'] = y_train\n",
    "top_words = eda_set.sum().sort_values(ascending = False)[:22]\n",
    "ru_set = eda_set[eda_set['ru'] == 1] / len(post_df1)\n",
    "mon_set = eda_set[eda_set['ru'] != 1] / len(post_df2)\n",
    "data_to_graph = pd.DataFrame({\n",
    "    'ru words': ru_set[top_words.index].sum()[1:]*100,\n",
    "    'monarchy words': mon_set[top_words.index].sum()[1:]*100\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Graph data collected above\n",
    "ig, ax = plt.subplots(figsize = (10,10) )\n",
    "\n",
    "# set height of bar\n",
    "bars1 = data_to_graph['ru words']\n",
    "bars2 = data_to_graph['monarchy words']\n",
    "\n",
    "y_pos = np.arange(len(bars1)*3)                           # create spots to put bars 0, 3, 6, etc for RU\n",
    "y_pos1 = np.arange(0, len(bars1)*3, 3)                    # spots 1, 4, 7, etc for monarcy \n",
    "y_pos2 = y_pos1 + 1                                       # leave 2, 5, 8, etc blank for esthetics\n",
    "words = top_words.index[1:]                               # these are the words being graphed, eliminated RDR tag\n",
    "ax.barh(y_pos1, bars1, align='center',\n",
    "        color='#66BF6A', ecolor='black', label = 'Rupaul')\n",
    "ax.barh(y_pos2, bars2, align='center',\n",
    "        color='#002A5C', ecolor='black', label = 'Monarchy')\n",
    "ax.set_yticks(y_pos1)\n",
    "ax.set_yticklabels(words)\n",
    "ax.invert_yaxis() \n",
    "ax.set_xlabel(\"Percent of Posts with Popular Word\")\n",
    "ax.set_ylabel(\"Popular Words in Subreddit Posts\")\n",
    "plt.legend(loc = 4)                                        #puts legend in bottom corner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic function to print out stats on grid search best model / parameters / fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_scores(grid_in, Xt = X_te_f, yt = y_test):\n",
    "    print(grid_in.best_params_)\n",
    "    print('Traing score:                 ', grid_in.best_score_)\n",
    "    print('Test score / Accuracy:        ', grid_in.score(Xt,yt))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(yt, grid_in.predict(Xt)))\n",
    "#    tn, fp, fn, tp = confusion_matrix(yt, grid_in.predict(Xt)).ravel()\n",
    "#    print('Accuracy:          ', (tn+tp)/(tn+tp+fn+fp), '     should equal test score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB and Logistic Models - with CountVectorizor & TDIFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vt__max_features': 5000, 'vt__ngram_range': (1, 3)}\n",
      "Traing score:                  0.9223300970873787\n",
      "Test score / Accuracy:         0.9321486268174475\n",
      "Confusion Matrix:\n",
      "[[214  35]\n",
      " [  7 363]]\n"
     ]
    }
   ],
   "source": [
    "pipe1a = Pipeline([\n",
    "    ('vt', CountVectorizer()),\n",
    "    ('lr', LogisticRegressionCV())\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'vt__max_features':[None, 4000, 5000],\n",
    "    'vt__ngram_range':[(1,1), (1,2), (1,3), (1,4), (1,5)]\n",
    "#    'vt__max_df':[1.0, .9],\n",
    "#    'vt__min_df':[0.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe1a, params_grid, verbose = 0, n_jobs = 2)\n",
    "grid.fit(X_tr_f, y_train.values.ravel())   # was getting a warning b/c shape - ravel()\n",
    "print_grid_scores(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tv__max_features': None, 'tv__ngram_range': (1, 5)}\n",
      "Traing score:                  0.9444444444444444\n",
      "Test score / Accuracy:         0.9515347334410339\n",
      "Confusion Matrix:\n",
      "[[231  18]\n",
      " [ 12 358]]\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([\n",
    "    ('tv', TfidfVectorizer()), \n",
    "    ('lr', LogisticRegressionCV())\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'tv__max_features':[None, 4000, 5000],\n",
    "    'tv__ngram_range':[(1,4), (1,5), (1,6)]\n",
    "}\n",
    "\n",
    "\n",
    "grid2 = GridSearchCV(pipe2, params_grid, verbose = 0, n_jobs = 2)\n",
    "grid2.fit(X_tr_f, y_train.values.ravel())   \n",
    "print_grid_scores(grid2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vt__max_features': None, 'vt__ngram_range': (1, 3)}\n",
      "Traing score:                  0.947680690399137\n",
      "Test score / Accuracy:         0.9644588045234249\n",
      "Confusion Matrix:\n",
      "[[236  13]\n",
      " [  9 361]]\n"
     ]
    }
   ],
   "source": [
    "pipe1b = Pipeline([\n",
    "    ('vt', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'vt__max_features':[None, 4000, 5000],\n",
    "    'vt__ngram_range':[(1,1), (1,2), (1,3), (1,4), (1,5)]\n",
    "#    'vt__max_df':[1.0, .9],\n",
    "#    'vt__min_df':[0.0]\n",
    "}\n",
    "\n",
    "grid1b = GridSearchCV(pipe1b, params_grid, verbose = 0, n_jobs = 3)\n",
    "grid1b.fit(X_tr_f, y_train.values.ravel())   # was getting a warning b/c shape - ravel()\n",
    "print_grid_scores(grid1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tv__max_features': 3000, 'tv__ngram_range': (1, 1)}\n",
      "Traing score:                  0.947680690399137\n",
      "Test score / Accuracy:         0.9515347334410339\n",
      "Confusion Matrix:\n",
      "[[226  23]\n",
      " [  7 363]]\n"
     ]
    }
   ],
   "source": [
    "pipe2b = Pipeline([\n",
    "    ('tv', TfidfVectorizer()), \n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'tv__max_features':[None, 2000, 3000, 3500],\n",
    "    'tv__ngram_range':[(1,1,), (1,2), (1,3)]\n",
    "}\n",
    "\n",
    "\n",
    "grid2 = GridSearchCV(pipe2b, params_grid, verbose = 0, n_jobs = 3)\n",
    "grid2.fit(X_tr_f, y_train.values.ravel())   \n",
    "print_grid_scores(grid2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pretty high scores already with MultinomialNB and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 45, 'vt__max_df': 0.975, 'vt__max_features': None, 'vt__min_df': 1, 'vt__ngram_range': (1, 4)}\n",
      "Traing score:                  0.9147788565264293\n",
      "Test score / Accuracy:         0.9305331179321487\n",
      "Confusion Matrix:\n",
      "[[209  40]\n",
      " [  3 367]]\n"
     ]
    }
   ],
   "source": [
    "pipe3 = Pipeline([\n",
    "    ('vt', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'vt__max_features':[None, 5000],\n",
    "    'vt__max_df':[.975, .97, .965],\n",
    "    'vt__min_df':[1],\n",
    "    'vt__ngram_range':[(1,2), (1,3), (1,4)],\n",
    "    'rf__n_estimators': [35, 40, 45]\n",
    "}\n",
    "\n",
    "grid3 = GridSearchCV(pipe3, params_grid, verbose = 0, n_jobs = 3)\n",
    "grid3.fit(X_tr_f, y_train.values.ravel())\n",
    "print_grid_scores(grid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 30, 'tv__max_df': 0.98, 'tv__max_features': None, 'tv__min_df': 2, 'tv__ngram_range': (1, 5)}\n",
      "Traing score:                  0.9115426105717368\n",
      "Test score / Accuracy:         0.9353796445880452\n",
      "Confusion Matrix:\n",
      "[[229  20]\n",
      " [ 20 350]]\n"
     ]
    }
   ],
   "source": [
    "pipe4 = Pipeline([\n",
    "    ('tv', TfidfVectorizer()), \n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'tv__max_features':[None, 5000],\n",
    "    'tv__max_df':[ .985, .98, .975],\n",
    "    'tv__min_df':[1, 2],\n",
    "    'tv__ngram_range':[(1,3), (1,4), (1,5)],\n",
    "    'rf__n_estimators': [30, 31, 32]\n",
    "}\n",
    "\n",
    "grid4 = GridSearchCV(pipe4, params_grid, verbose = 0, n_jobs = 3)\n",
    "grid4.fit(X_tr_f, y_train.values.ravel())\n",
    "print_grid_scores(grid4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ada__learning_rate': 0.85, 'ada__n_estimators': 75, 'vt__ngram_range': (1, 1)}\n",
      "Traing score:                  0.8980582524271845\n",
      "Test score / Accuracy:         0.9143780290791599\n",
      "Confusion Matrix:\n",
      "[[205  44]\n",
      " [  9 361]]\n"
     ]
    }
   ],
   "source": [
    "pipe6 = Pipeline([\n",
    "    ('vt', CountVectorizer()),\n",
    "    ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "ada_params = {\n",
    "    'vt__ngram_range':[(1,1), (1,2), (1,3), (1,4)],\n",
    "    'ada__n_estimators': [70, 75, 80],\n",
    "    'ada__learning_rate':[.85, .9, .95]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe6, param_grid = ada_params, n_jobs = 3)\n",
    "gs.fit(X_tr_f, y_train.values.ravel())\n",
    "print_grid_scores(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ada__learning_rate': 1, 'ada__n_estimators': 243, 'tv__max_features': 2050, 'tv__ngram_range': (1, 3)}\n",
      "Traing score:                  0.9007551240560949\n",
      "Test score / Accuracy:         0.925686591276252\n",
      "Confusion Matrix:\n",
      "[[216  33]\n",
      " [ 13 357]]\n"
     ]
    }
   ],
   "source": [
    "pipe7 = Pipeline([\n",
    "    ('tv', TfidfVectorizer()), \n",
    "    ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'tv__max_features':[2000, 2050, 2100, 2200],\n",
    "    'tv__ngram_range':[(1,3), (1,4), (1,5)],\n",
    "#    'tv__max_df':[ 1.0, .95],\n",
    "#    'tv__min_df':[1, 2],\n",
    "    'ada__n_estimators': [240, 243, 245, 247],\n",
    "    'ada__learning_rate':[1, .93, .92, .91]    \n",
    "}\n",
    "\n",
    "grid7 = GridSearchCV(pipe7, params_grid, verbose = 0, n_jobs = 3)\n",
    "grid7.fit(X_tr_f, y_train.values.ravel())   \n",
    "print_grid_scores(grid7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bag__n_estimators': 50, 'vt__max_df': 1.0, 'vt__max_features': None, 'vt__ngram_range': (1, 1)}\n",
      "Traing score:                  0.9002157497303128\n",
      "Test score / Accuracy:         0.9176090468497576\n",
      "Confusion Matrix:\n",
      "[[209  40]\n",
      " [ 11 359]]\n"
     ]
    }
   ],
   "source": [
    "pipe5 = Pipeline([\n",
    "    ('vt', CountVectorizer()),\n",
    "    ('bag',BaggingClassifier())\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'vt__ngram_range':[(1,1), (1,2)],\n",
    "    'vt__max_features':[None],\n",
    "    'vt__max_df':[ .9, 1.0],\n",
    "#    'vt__min_df':[1, 2, 3],\n",
    "    'bag__n_estimators': [50, 75, 100, 250, 500]\n",
    "}\n",
    "\n",
    "grid5 = GridSearchCV(pipe5, params_grid, verbose = 0, n_jobs = 3)\n",
    "grid5.fit(X_tr_f, y_train.values.ravel())\n",
    "print_grid_scores(grid5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gb__learning_rate': 0.8, 'gb__loss': 'exponential', 'gb__max_depth': 4, 'gb__max_features': None, 'gb__n_estimators': 3000, 'gb__subsample': 1.0, 'tv__max_df': 1.0, 'tv__max_features': None, 'tv__min_df': 3, 'tv__ngram_range': (1, 3)}\n",
      "Traing score:                  0.9115426105717368\n",
      "Test score / Accuracy:         0.9305331179321487\n",
      "Confusion Matrix:\n",
      "[[218  31]\n",
      " [ 12 358]]\n"
     ]
    }
   ],
   "source": [
    "pipe8 = Pipeline([\n",
    "    ('tv', TfidfVectorizer()), \n",
    "    ('gb', GradientBoostingClassifier(random_state = 1929))\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'tv__ngram_range':[(1,2), (1,3), (1,4)],\n",
    "    'tv__max_features':[None],\n",
    "    'tv__max_df':[ 1.0, .95],\n",
    "    'tv__min_df':[2, 3],\n",
    "    'gb__max_depth': [3, 4],\n",
    "    'gb__loss':['exponential'],\n",
    "#    'gb__criterion':['friedman_mse', 'mse', 'mae'],\n",
    "    'gb__learning_rate':[.9, .8, .7],\n",
    "    'gb__n_estimators': [1000, 2000, 3000] ,\n",
    "    'gb__subsample':[1.0],\n",
    "    'gb__max_features':[None]\n",
    "}\n",
    "\n",
    "grid8 = GridSearchCV(pipe8, params_grid, verbose = 0, n_jobs = 3)\n",
    "grid8.fit(X_tr_f, y_train.values.ravel())   \n",
    "print_grid_scores(grid8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall, the Naive Bayes Model with Count Vectorizer was Best Performing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The fit is relatively good at above 96% accuracy on the testing set.  Accuracy of 94-95% on the training set.  Since these values are close, it implies a nice fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing the Misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This printout below shows posts that were misclassified in the test dataset by the best model (grid1b, NB with CV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "      <th>Misclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>dont want puppet menteri besar raja perlis</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>clinic near start free std screening</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>work hospital family asks prognosis</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>thought wa kinda funny replace prodemocracy an...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>feed horse</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>soooo ive found product supermarket spain</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>la royale french royalist song</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>wa robin williams defining role</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>weve hit subscriber post subscriber httpsmyout...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>saw showerthoughts immediately meme came mind</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>queen shitposts crown majesty</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>queen aishwarya nepal revered bada maharani</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>queen rania meet qrta teacher trainee amman sc...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>cometh hour cometh woman queen saved commonwealth</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>revealed teenager tried assassinate queen shoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>people tell welcome crib visit house</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>queen calm confidence traced single tip mother</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>katie hopkins twitter competition cant buy cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>discussion country netflixes season usa none k...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>love quote much</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>poll find think sub monarchism general open ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>queen officially unveils new highland game pav...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X  y  yhat  Misclass\n",
       "1819         dont want puppet menteri besar raja perlis  0     1         1\n",
       "320                clinic near start free std screening  1     0         1\n",
       "951                 work hospital family asks prognosis  1     0         1\n",
       "1610  thought wa kinda funny replace prodemocracy an...  0     1         1\n",
       "364                                          feed horse  1     0         1\n",
       "442           soooo ive found product supermarket spain  1     0         1\n",
       "1869                     la royale french royalist song  0     1         1\n",
       "434                     wa robin williams defining role  1     0         1\n",
       "1680  weve hit subscriber post subscriber httpsmyout...  0     1         1\n",
       "520       saw showerthoughts immediately meme came mind  1     0         1\n",
       "355                       queen shitposts crown majesty  1     0         1\n",
       "2000        queen aishwarya nepal revered bada maharani  0     1         1\n",
       "2182  queen rania meet qrta teacher trainee amman sc...  0     1         1\n",
       "2004  cometh hour cometh woman queen saved commonwealth  0     1         1\n",
       "2329  revealed teenager tried assassinate queen shoc...  0     1         1\n",
       "295                people tell welcome crib visit house  1     0         1\n",
       "2228     queen calm confidence traced single tip mother  0     1         1\n",
       "1852  katie hopkins twitter competition cant buy cla...  0     1         1\n",
       "1052  discussion country netflixes season usa none k...  1     0         1\n",
       "2291                                    love quote much  0     1         1\n",
       "2449  poll find think sub monarchism general open ne...  0     1         1\n",
       "1493  queen officially unveils new highland game pav...  0     1         1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = grid1b.predict(X_te_f)\n",
    "df_out = pd.DataFrame({\n",
    "    'X':X_te_f,\n",
    "    'y':y_test['y'],\n",
    "    'yhat':yhat\n",
    "})\n",
    "\n",
    "df_out['Misclass'] = abs(df_out['y'] - df_out['yhat'])\n",
    "df_out[df_out['Misclass']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting specific phrases -- which subreddit would this phrase be most likely to show up in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_phrase(list_in, grid_in = grid1b):\n",
    "    n = max([len(each) for each in list_in])\n",
    "    for each in list_in:\n",
    "        pr = grid_in.predict([each])\n",
    "        print(each, end = ' ' * (n+4 - len(each)))\n",
    "        if pr:\n",
    "            print (\"Rupaul\")\n",
    "        else:\n",
    "            print (\"General Monarchy\")\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_test = ['queen', 'mother', 'queen mother', 'coronation', 'crown', 'elizabeth', 'william', 'willam', 'miss vanjy didnt get a crown', 'work', 'work william', 'catherine work', 'jubilee', 'jujube']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen                           Rupaul\n",
      " \n",
      "mother                          Rupaul\n",
      " \n",
      "queen mother                    Rupaul\n",
      " \n",
      "coronation                      General Monarchy\n",
      " \n",
      "crown                           General Monarchy\n",
      " \n",
      "elizabeth                       General Monarchy\n",
      " \n",
      "william                         General Monarchy\n",
      " \n",
      "willam                          Rupaul\n",
      " \n",
      "miss vanjy didnt get a crown    Rupaul\n",
      " \n",
      "work                            Rupaul\n",
      " \n",
      "work william                    General Monarchy\n",
      " \n",
      "catherine work                  General Monarchy\n",
      " \n",
      "jubilee                         General Monarchy\n",
      " \n",
      "jujube                          Rupaul\n",
      " \n"
     ]
    }
   ],
   "source": [
    "pred_phrase(list_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How close is The Crown reddit to either Rupaul or Monarchist?  Slightly over 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5459459459459459\n"
     ]
    }
   ],
   "source": [
    "print(grid1b.predict(X_crown).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In general, I was surprised that a more simple model (Naive Bayes) was the most powerful predictor.  I did a lot of hypertuning of parameters on the ensemble models, but they never reached the level of predicting power than either NB or Logistic regression had.\n",
    "\n",
    "> The initial score for a basic model without much advanced analysis was just under 90%.  After initial model building, testing and parameter tuning, I reached a score of 93% on NB and 90-92% on other models.  A second pass at the process yieled two additional areas where I could make changes:  eliminating records that had all stop words and so were blank data going through the model, and tuning on ngrams.  The ngram tuning provided a 2.5% boost to my best model and the removal of the blank posts added another 0.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One final model - testing what we learned in class on Friday\n",
    "\n",
    "### Using a sentiment analyzer, the score was unchanged.  Using average word length or post length, the predictive power of the model decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores('hi how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosScore(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_pos(self, line):\n",
    "        return sia.polarity_scores(line)['pos']\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return np.array(df.apply(self.get_pos)).reshape(-1,1)\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageWordLength(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def avg_word_length(self, line):\n",
    "        return np.mean([len(each) for each in line.split()])\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return np.array(df.apply(self.avg_word_length)).reshape(-1,1)\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostLength(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def post_length(self, line):\n",
    "        return len(line) \n",
    "    \n",
    "    def transform(self, df):\n",
    "        return np.array(df.apply(self.post_length)).reshape(-1,1)\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967637540453075 0.9644588045234249\n"
     ]
    }
   ],
   "source": [
    "pipe55 = Pipeline([\n",
    "    ('fu', FeatureUnion([\n",
    "        ('cv', CountVectorizer(ngram_range=(1,3))),\n",
    "#        ('awl', AverageWordLength()),\n",
    "#        ('gc', PosScore()),\n",
    "#        ('pl', PostLength())\n",
    "    ])),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe55.fit(X_tr_f, y_train.values.ravel())\n",
    "print(pipe55.score(X_tr_f, y_train), pipe55.score(X_te_f, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
